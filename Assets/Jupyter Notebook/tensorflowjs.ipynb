{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "const dfd = require(\"danfojs-node\");\n",
    "const tf = dfd.tensorflow\n",
    "// const tf = require('@tensorflow/tfjs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  rowStart: 7228,\n",
       "  rowEnd: 7288,\n",
       "  timesteps: 2,\n",
       "  maxBatchSize: 13,\n",
       "  layerSize: 1,\n",
       "  unitSize: 1,\n",
       "  dropout: 0,\n",
       "  learningRate: 0.1,\n",
       "  maxEpochs: 1,\n",
       "  timeCol: 'tanggal',\n",
       "  feature: [ 'rr' ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "  rowStart: 7228,\n",
    "  rowEnd: 7288,\n",
    "  timesteps: 2,\n",
    "  maxBatchSize: 13,\n",
    "  layerSize: 1,\n",
    "  unitSize: 1,\n",
    "  dropout: 0,\n",
    "  learningRate: 0.1,\n",
    "  maxEpochs: 1,\n",
    "  timeCol: 'tanggal',\n",
    "  feature: ['rr']\n",
    "}\n",
    "\n",
    "// usecols = [config.timeCol].concat(config.feature)\n",
    "\n",
    "function trainTestSplit(dataset, timeStep = 1) {\n",
    "  dataX = []\n",
    "  dataY = []\n",
    "\n",
    "  // for (let i = 0; i < dataset.values.length - timeStep - 1; i++) {\n",
    "  for (let i = 0; i < dataset.values.length - timeStep; i++) {\n",
    "    dataX.push(dataset.iloc({ rows: [`${i}:${i + timeStep}`] }).values)\n",
    "    dataY.push(dataset.iloc({ rows: [i + timeStep] }).values[0])\n",
    "  }\n",
    "\n",
    "  return [dataX, dataY]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ 60, 11 ]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$$async$$ = true;\n",
    "(async function () {\n",
    "  dataset = await dfd.readCSV(\"../Data/1985-2021.csv\")\n",
    "  dataset = dataset.iloc({rows:[`${config.rowStart}:${config.rowEnd}`]})\n",
    "  datelist = dataset.loc({columns: [config.timeCol]})\n",
    "\n",
    "  $$done$$(dataset.shape)\n",
    "})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor {\n",
       "  kept: false,\n",
       "  isDisposedInternal: false,\n",
       "  shape: [ 4, 1, 2 ],\n",
       "  dtype: 'float32',\n",
       "  size: 8,\n",
       "  strides: [ 2, 2 ],\n",
       "  dataId: {},\n",
       "  id: 18,\n",
       "  rankType: '3',\n",
       "  scopeId: 6\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureset = dataset.loc({columns: config.feature})\n",
    "\n",
    "scaller = new dfd.MinMaxScaler()\n",
    "scaller.fit(featureset)\n",
    "\n",
    "featuresetScaled = scaller.transform(featureset)\n",
    "\n",
    "trainSize = featuresetScaled.values.length * 0.9\n",
    "trainset = featuresetScaled.iloc({rows: [`${0}:${trainSize}`]})\n",
    "testset =  featuresetScaled.iloc({rows: [`${trainSize}:${featuresetScaled.values.length}`]})\n",
    "\n",
    "trainset = trainTestSplit(trainset, timeStep=config.timesteps)\n",
    "testset = trainTestSplit(testset, timeStep=config.timesteps)\n",
    "\n",
    "XTrain = tf.tensor(trainset[0])\n",
    "yTrain = tf.tensor(trainset[1])\n",
    "\n",
    "XTest = tf.tensor(testset[0])\n",
    "yTest = tf.tensor(testset[1])\n",
    "\n",
    "XTrain = tf.reshape(XTrain, [XTrain.shape[0], config.feature.length, XTrain.shape[1]])\n",
    "XTest = tf.reshape(XTest, [XTest.shape[0], config.feature.length, XTest.shape[1]])\n",
    "\n",
    "// XTrain = tf.reshape(XTrain, [4,13, 1, 2])\n",
    "// yTrain = tf.reshape(yTrain, [4,13, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ 52, 1, 2 ]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ 52, 1 ]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tf.train.gdo is not a function",
     "output_type": "error",
     "traceback": [
      "evalmachine.<anonymous>:27",
      "  optimizer: tf.train.gdo(config.learningRate),",
      "                      ^",
      "",
      "TypeError: tf.train.gdo is not a function",
      "    at evalmachine.<anonymous>:27:23",
      "    at Script.runInThisContext (node:vm:129:12)",
      "    at Object.runInThisContext (node:vm:305:38)",
      "    at run ([eval]:1020:15)",
      "    at onRunRequest ([eval]:864:18)",
      "    at onMessage ([eval]:828:13)",
      "    at process.emit (node:events:390:28)",
      "    at emit (node:internal/child_process:917:12)",
      "    at processTicksAndRejections (node:internal/process/task_queues:84:21)"
     ]
    }
   ],
   "source": [
    "yPredLoss = []\n",
    "yTrueLoss = []\n",
    "\n",
    "model = tf.sequential()\n",
    "\n",
    "model.add(tf.layers.lstm({\n",
    "  units: config.unitSize,\n",
    "  batchSize: config.maxBatchSize,\n",
    "  inputShape: [config.feature.length, config.timesteps],\n",
    "  goBackwards: true,\n",
    "  dropout: config.dropout,\n",
    "  weights: [\n",
    "    tf.tensor([\n",
    "      [0.5774, 0.5774, 0.5774, 0.5774],\n",
    "      [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "    ]),\n",
    "    tf.tensor([\n",
    "      [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "    ]),\n",
    "    tf.zeros([4])\n",
    "  ]\n",
    "}))\n",
    "\n",
    "// model.layers[0].getWeights()[0].print()\n",
    "\n",
    "model.compile({\n",
    "  optimizer: tf.train.GradientDescentOptimizer(config.learningRate),\n",
    "  // loss: 'meanSquaredError',\n",
    "  loss: function (yTrue, yPred) {\n",
    "    yPredLoss.push(yPred.array())\n",
    "    yTrueLoss.push(yTrue.array())\n",
    "    return tf.losses.meanSquaredError(yTrue, yPred)\n",
    "  },\n",
    "  runEagerly: true\n",
    "})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220ms 4232us/step - loss=0.0824 \n"
     ]
    }
   ],
   "source": [
    "batchLoss = []\n",
    "\n",
    "$$async$$ = true;\n",
    "(async function () {\n",
    "  history = await model.fit(XTrain, yTrain, {\n",
    "    shuffle: false,\n",
    "    epochs: config.maxEpochs,\n",
    "    verbose: 1,\n",
    "    batchSize: config.maxBatchSize,\n",
    "    callbacks: [\n",
    "      new tf.CustomCallback({\n",
    "        onBatchEnd: function (batch, logs = null) {\n",
    "          batchLoss.push(logs)\n",
    "        }\n",
    "      })\n",
    "    ]\n",
    "  })\n",
    "  $$done$$();\n",
    "})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  { batch: 0, size: 13, loss: 0.11157790571451187 },\n",
       "  { batch: 1, size: 13, loss: 0.04249683767557144 },\n",
       "  { batch: 2, size: 13, loss: 0.08604662120342255 },\n",
       "  { batch: 3, size: 13, loss: 0.08932735025882721 }\n",
       "]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Promise {\n",
       "  [\n",
       "    [ 0.003764435416087508 ],\n",
       "    [ 0.19518616795539856 ],\n",
       "    [ 0.3006698787212372 ],\n",
       "    [ 0.2219531536102295 ],\n",
       "    [ 0.16048069298267365 ],\n",
       "    [ 0.05620086193084717 ],\n",
       "    [ 0.04501638934016228 ],\n",
       "    [ 0.030724365264177322 ],\n",
       "    [ 0.0031562268268316984 ],\n",
       "    [ 0.024033837020397186 ],\n",
       "    [ 0.03903147950768471 ],\n",
       "    [ 0.061161961406469345 ],\n",
       "    [ 0.07305235415697098 ]\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPredLoss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Promise {\n",
       "  [\n",
       "    [ 1 ],\n",
       "    [ 0.5257731676101685 ],\n",
       "    [ 0.6206185817718506 ],\n",
       "    [ 0.23711340129375458 ],\n",
       "    [ 0.10309278219938278 ],\n",
       "    [ 0.17525772750377655 ],\n",
       "    [ 0.020618556067347527 ],\n",
       "    [ 0.0010309278732165694 ],\n",
       "    [ 0.15463916957378387 ],\n",
       "    [ 0.08969072252511978 ],\n",
       "    [ 0.2773195803165436 ],\n",
       "    [ 0.15257732570171356 ],\n",
       "    [ 0.4402061998844147 ]\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrueLoss[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
