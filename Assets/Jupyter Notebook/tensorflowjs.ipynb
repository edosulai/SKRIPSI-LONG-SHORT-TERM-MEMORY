{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "const dfd = require(\"danfojs-node\");\n",
    "const tf = dfd.tensorflow\n",
    "// const tf = require('@tensorflow/tfjs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  rowStart: 7228,\n",
       "  rowEnd: 7288,\n",
       "  timesteps: 2,\n",
       "  maxBatchSize: 1,\n",
       "  layerSize: 1,\n",
       "  unitSize: 1,\n",
       "  dropout: 0,\n",
       "  learningRate: 0.1,\n",
       "  maxEpochs: 50,\n",
       "  timeCol: 'tanggal',\n",
       "  feature: [ 'rr' ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "  rowStart: 7228,\n",
    "  rowEnd: 7288,\n",
    "  timesteps: 2,\n",
    "  maxBatchSize: 1,\n",
    "  layerSize: 1,\n",
    "  unitSize: 1,\n",
    "  dropout: 0,\n",
    "  learningRate: 0.1,\n",
    "  maxEpochs: 50,\n",
    "  timeCol: 'tanggal',\n",
    "  feature: ['rr']\n",
    "}\n",
    "\n",
    "// usecols = [config.timeCol].concat(config.feature)\n",
    "\n",
    "function trainTestSplit(dataset, timeStep = 1) {\n",
    "  dataX = []\n",
    "  dataY = []\n",
    "\n",
    "  // for (let i = 0; i < dataset.values.length - timeStep - 1; i++) {\n",
    "  for (let i = 0; i < dataset.values.length - timeStep; i++) {\n",
    "    dataX.push(dataset.iloc({ rows: [`${i}:${i + timeStep}`] }).values)\n",
    "    dataY.push(dataset.iloc({ rows: [i + timeStep] }).values[0])\n",
    "  }\n",
    "\n",
    "  return [dataX, dataY]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ 60, 11 ]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$$async$$ = true;\n",
    "(async function () {\n",
    "  dataset = await dfd.readCSV(\"../Data/1985-2021.csv\")\n",
    "  dataset = dataset.iloc({rows:[`${config.rowStart}:${config.rowEnd}`]})\n",
    "  datelist = dataset.loc({columns: [config.timeCol]})\n",
    "\n",
    "  $$done$$(dataset.shape)\n",
    "})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor {\n",
       "  kept: false,\n",
       "  isDisposedInternal: false,\n",
       "  shape: [ 4, 1, 2 ],\n",
       "  dtype: 'float32',\n",
       "  size: 8,\n",
       "  strides: [ 2, 2 ],\n",
       "  dataId: {},\n",
       "  id: 18,\n",
       "  rankType: '3',\n",
       "  scopeId: 6\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureset = dataset.loc({columns: config.feature})\n",
    "\n",
    "scaller = new dfd.MinMaxScaler()\n",
    "scaller.fit(featureset)\n",
    "\n",
    "featuresetScaled = scaller.transform(featureset)\n",
    "\n",
    "trainSize = featuresetScaled.values.length * 0.9\n",
    "trainset = featuresetScaled.iloc({rows: [`${0}:${trainSize}`]})\n",
    "testset =  featuresetScaled.iloc({rows: [`${trainSize}:${featuresetScaled.values.length}`]})\n",
    "\n",
    "trainset = trainTestSplit(trainset, timeStep=config.timesteps)\n",
    "testset = trainTestSplit(testset, timeStep=config.timesteps)\n",
    "\n",
    "XTrain = tf.tensor(trainset[0])\n",
    "yTrain = tf.tensor(trainset[1])\n",
    "\n",
    "XTest = tf.tensor(testset[0])\n",
    "yTest = tf.tensor(testset[1])\n",
    "\n",
    "XTrain = tf.reshape(XTrain, [XTrain.shape[0], config.feature.length, XTrain.shape[1]])\n",
    "XTest = tf.reshape(XTest, [XTest.shape[0], config.feature.length, XTest.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________\n",
      "Layer (type)                Input Shape               Output shape              Param #   \n",
      "==========================================================================================\n",
      "lstm_LSTM1 (LSTM)           [[1,1,2]]                 [1,1]                     16        \n",
      "==========================================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "// yPredLoss = []\n",
    "// yTrueLoss = []\n",
    "// loss = []\n",
    "\n",
    "// function meanSquaredError(yTrue, yPred) {\n",
    "//   yPredLoss.push(yPred.array())\n",
    "//   yTrueLoss.push(yTrue.array())\n",
    "//   loss.push(tf.losses.meanSquaredError(yTrue, yPred).arraySync())\n",
    "//   return tf.losses.meanSquaredError(yTrue, yPred)\n",
    "// }\n",
    "\n",
    "model = tf.sequential()\n",
    "\n",
    "model.add(tf.layers.lstm({\n",
    "  units: config.unitSize,\n",
    "  batchInputShape: [config.maxBatchSize, config.feature.length, config.timesteps],\n",
    "  goBackwards: true,\n",
    "  dropout: config.dropout,\n",
    "  weights: [\n",
    "    tf.tensor([\n",
    "      [0.5774, 0.5774, 0.5774, 0.5774],\n",
    "      [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "    ]),\n",
    "    tf.tensor([\n",
    "      [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "    ]),\n",
    "    tf.zeros([4])\n",
    "  ]\n",
    "}))\n",
    "\n",
    "// model.layers[0].getWeights()[0].print()\n",
    "\n",
    "model.compile({\n",
    "  optimizer: tf.train.sgd(config.learningRate),\n",
    "  loss: 'meanSquaredError',\n",
    "  // loss: meanSquaredError,\n",
    "  runEagerly: true\n",
    "})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// batchEnd = []\n",
    "epochEnd = []\n",
    "\n",
    "$$async$$ = true;\n",
    "(async function () {\n",
    "  history = await model.fit(XTrain, yTrain, {\n",
    "    shuffle: false,\n",
    "    epochs: config.maxEpochs,\n",
    "    verbose: 1,\n",
    "    batchSize: config.maxBatchSize,\n",
    "    callbacks: [\n",
    "      new tf.CustomCallback({\n",
    "        // onEpochBegin: null,\n",
    "        onEpochEnd: (epoch, logs = null) => epochEnd.push(logs.loss),\n",
    "        // on_batch_begin: null,\n",
    "        // onBatchEnd: (batch, logs = null) => batchEnd.push(logs.loss),\n",
    "        // onTrainBegin: null,\n",
    "        // onTrainEnd: null,\n",
    "      })\n",
    "    ]\n",
    "  })\n",
    "  $$done$$()\n",
    "})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "// $$async$$ = true;\n",
    "// (async function () {\n",
    "//   await Promise.all(yPredLoss).then(values => {\n",
    "//     console.log(values);\n",
    "//   });\n",
    "//   $$done$$()\n",
    "// })()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float32Array(4) [\n",
       "  0.1997341513633728,\n",
       "  0.187837153673172,\n",
       "  0.18746259808540344,\n",
       "  0.18775293231010437\n",
       "]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTest, yTest).dataSync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float32Array(1) [ 0.03289681673049927 ]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBatchEnd = []\n",
    "\n",
    "model.evaluate(XTest, yTest, {\n",
    "  callbacks: [\n",
    "    new tf.CustomCallback({\n",
    "      onBatchEnd: (batch, logs = null) => testBatchEnd.push(logs.loss),\n",
    "    })\n",
    "  ]\n",
    "}).dataSync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBatchEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
