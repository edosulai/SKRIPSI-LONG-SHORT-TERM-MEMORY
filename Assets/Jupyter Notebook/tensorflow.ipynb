{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def set_config(config_dict):\n",
    "    config = Config()\n",
    "    config.__dict__ = config_dict\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    'row_start': 7228,\n",
    "    'row_end': 7288,\n",
    "    \"timesteps\": 2,\n",
    "    \"max_batch_size\": 1,\n",
    "    \"layer_size\": 2,\n",
    "    \"unit_size\": 1,\n",
    "    \"dropout\": 0,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_epochs\": 1,\n",
    "    \"time_col\": 'tanggal',\n",
    "    \"feature\": ['rr']\n",
    "})\n",
    "\n",
    "\n",
    "def train_test_split(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    # for i in range(len(dataset)-time_step-1):\n",
    "    for i in range(len(dataset)-time_step):\n",
    "        dataX.append(dataset[i:(i+time_step), 0])\n",
    "        dataY.append(dataset[i+time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Data/1985-2021.csv').replace(to_replace=[8888, 9999, 2555], value=np.nan)[config.row_start:config.row_end]\n",
    "dataset.interpolate(inplace=True)\n",
    "\n",
    "datelist = [datetime.strptime(date, '%Y-%m-%d').date() for date in list(dataset[config.time_col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset[config.feature]\n",
    "vector_featureset = featureset.values\n",
    "\n",
    "scaller = MinMaxScaler()\n",
    "vector_featureset_scaled = scaller.fit_transform(vector_featureset)\n",
    "\n",
    "train_size = int(vector_featureset_scaled.size * 0.9)\n",
    "trainset, testset = vector_featureset_scaled[0:train_size], vector_featureset_scaled[train_size:vector_featureset_scaled.size]\n",
    "\n",
    "X_train, y_train = train_test_split(trainset, time_step=config.timesteps)\n",
    "X_test, y_test = train_test_split(testset, time_step=config.timesteps)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], len(config.feature), X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], len(config.feature), X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (1, 1, 1)                 16        \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (1, 1)                    12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28\n",
      "Trainable params: 28\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[array([[ 0.96612954,  0.5867425 ,  0.5229045 , -0.3984329 ]],\n",
      "      dtype=float32), array([[ 0.26341128, -0.02856461,  0.92797273, -0.26204062]],\n",
      "      dtype=float32), array([0., 1., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# y_pred_loss = list()\n",
    "# y_true_loss = list()\n",
    "# loss = list()\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    # y_pred_loss.append(y_pred)\n",
    "    # y_true_loss.append(y_true)\n",
    "    # loss.append(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true)))\n",
    "    return tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(mean_squared_error(y_pred, y_true))\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "for i in range(0, config.layer_size):\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            units=config.unit_size,\n",
    "            return_sequences=False if i == config.layer_size - 1 else True,\n",
    "            batch_input_shape=(config.max_batch_size, len(config.feature), config.timesteps),\n",
    "            go_backwards=True,\n",
    "            dropout=config.dropout,\n",
    "            # weights=[\n",
    "            #     np.array([\n",
    "            #         [0.5774, 0.5774, 0.5774, 0.5774],\n",
    "            #         [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "            #     ]),\n",
    "            #     np.array([\n",
    "            #         [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "            #     ]),\n",
    "            #     np.zeros([4])\n",
    "            # ]\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=config.learning_rate),\n",
    "        loss=mean_squared_error,\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "print(model.layers[1].get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 40ms/step - loss: 0.0964\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "batch_loss = list()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    shuffle=False,\n",
    "    epochs=config.max_epochs,\n",
    "    verbose=1,\n",
    "    batch_size=config.max_batch_size,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_begin=None,\n",
    "            on_epoch_end=None,\n",
    "            on_batch_begin=None,\n",
    "            on_batch_end=lambda batch, logs=None: batch_loss.append(logs['loss']),\n",
    "            on_train_begin=None,\n",
    "            on_train_end=None,\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.000861406326294,\n",
       " 0.6438044309616089,\n",
       " 0.5689262747764587,\n",
       " 0.4417469799518585,\n",
       " 0.355497270822525,\n",
       " 0.3002797067165375,\n",
       " 0.25738605856895447,\n",
       " 0.22528739273548126,\n",
       " 0.20195704698562622,\n",
       " 0.18210595846176147,\n",
       " 0.17124976217746735,\n",
       " 0.1582501381635666,\n",
       " 0.15931902825832367,\n",
       " 0.14880333840847015,\n",
       " 0.13899938762187958,\n",
       " 0.13146844506263733,\n",
       " 0.1250218003988266,\n",
       " 0.12078744918107986,\n",
       " 0.11789202690124512,\n",
       " 0.1143995150923729,\n",
       " 0.10899513214826584,\n",
       " 0.10464102774858475,\n",
       " 0.10095265507698059,\n",
       " 0.09674959629774094,\n",
       " 0.10980334877967834,\n",
       " 0.10558585077524185,\n",
       " 0.10437968373298645,\n",
       " 0.11295115947723389,\n",
       " 0.11014033854007721,\n",
       " 0.11484004557132721,\n",
       " 0.11116813123226166,\n",
       " 0.1077926829457283,\n",
       " 0.10471247881650925,\n",
       " 0.10172402113676071,\n",
       " 0.0988866463303566,\n",
       " 0.1128869354724884,\n",
       " 0.1099226176738739,\n",
       " 0.10869266092777252,\n",
       " 0.10604213178157806,\n",
       " 0.10354752838611603,\n",
       " 0.10106594115495682,\n",
       " 0.10332410782575607,\n",
       " 0.10094572603702545,\n",
       " 0.09876785427331924,\n",
       " 0.096573106944561,\n",
       " 0.10517173260450363,\n",
       " 0.10302364826202393,\n",
       " 0.10094588994979858,\n",
       " 0.09908371418714523,\n",
       " 0.0999879240989685,\n",
       " 0.09813980758190155,\n",
       " 0.09639151394367218]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ec44ab71e55dcbd77e8108daeda65d530bc364476bc79d734b0ae94bd7b36be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
