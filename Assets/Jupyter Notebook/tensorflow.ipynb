{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def set_config(config_dict):\n",
    "    config = Config()\n",
    "    config.__dict__ = config_dict\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    'row_start': 7228,\n",
    "    'row_end': 7288,\n",
    "    \"timesteps\": 2,\n",
    "    # \"max_batch_size\": 13,\n",
    "    \"max_batch_size\": 1,\n",
    "    \"layer_size\": 1,\n",
    "    \"unit_size\": 1,\n",
    "    \"dropout\": 0,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_epochs\": 1,\n",
    "    \"time_col\": 'tanggal',\n",
    "    \"feature\": ['rr']\n",
    "})\n",
    "\n",
    "# usecols = [*[config.time_col], *config.feature]\n",
    "\n",
    "\n",
    "def train_test_split(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    # for i in range(len(dataset)-time_step-1):\n",
    "    for i in range(len(dataset)-time_step):\n",
    "        dataX.append(dataset[i:(i+time_step), 0])\n",
    "        dataY.append(dataset[i+time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Data/1985-2021.csv').replace(to_replace=[8888, 9999, 2555], value=np.nan)[config.row_start:config.row_end]\n",
    "dataset.interpolate(inplace=True)\n",
    "\n",
    "datelist = [datetime.strptime(date, '%Y-%m-%d').date() for date in list(dataset[config.time_col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = dataset[config.feature]\n",
    "vector_featureset = featureset.values\n",
    "\n",
    "scaller = MinMaxScaler()\n",
    "vector_featureset_scaled = scaller.fit_transform(vector_featureset)\n",
    "\n",
    "train_size = int(vector_featureset_scaled.size * 0.9)\n",
    "trainset, testset = vector_featureset_scaled[0:train_size], vector_featureset_scaled[train_size:vector_featureset_scaled.size]\n",
    "\n",
    "X_train, y_train = train_test_split(trainset, time_step=config.timesteps)\n",
    "# X_test, y_test = train_test_split(testset, time_step=config.timesteps)\n",
    "# (51, 2)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], len(config.feature), X_train.shape[1]))\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], len(config.feature)))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], len(config.feature), X_test.shape[1]))\n",
    "# (51, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (1, 1)                    16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "y_pred_loss = list()\n",
    "y_true_loss = list()\n",
    "loss = list()\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    y_pred_loss.append(y_pred)\n",
    "    y_true_loss.append(y_true)\n",
    "    loss.append(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true)))\n",
    "    return tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true))\n",
    "    # return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(mean_squared_error(y_pred, y_true))\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential()\n",
    "\n",
    "# for i in range(0, config.layer_size):\n",
    "#     model.add(tf.keras.layers.LSTM(\n",
    "#         units=config.unit_size,\n",
    "#         return_sequences=False if i == config.layer_size - 1 else True,\n",
    "#         input_shape=(config.timesteps, 1),\n",
    "#         go_backwards=True,\n",
    "#         dropout=config.dropout,\n",
    "#         weights=[\n",
    "#             np.float32([[0.5774, 0.5774, 0.5774, 0.5774]]),\n",
    "#             np.float32([[0.5774, 0.5774, 0.5774, 0.5774]]),\n",
    "#             np.float32([0, 0, 0, 0])\n",
    "#         ],\n",
    "#     ))\n",
    "# else:\n",
    "#     # model.compile(optimizer=SGD(learning_rate=config.learning_rate), loss=root_mean_squared_error)\n",
    "#     print(model.get_weights())\n",
    "#     model.compile(optimizer=SGD(learning_rate=config.learning_rate), loss='mean_squared_error')\n",
    "#     model.summary()\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(\n",
    "    units=config.unit_size,\n",
    "    batch_input_shape=(config.max_batch_size, len(config.feature), config.timesteps),\n",
    "    go_backwards=True,\n",
    "    dropout=config.dropout,\n",
    "    weights=[\n",
    "        np.array([\n",
    "            [0.5774, 0.5774, 0.5774, 0.5774],\n",
    "            [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "        ]),\n",
    "        np.array([\n",
    "            [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "        ]),\n",
    "        np.zeros([4])\n",
    "    ],\n",
    "))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=config.learning_rate),\n",
    "    loss=mean_squared_error,\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 37ms/step - loss: 0.0797\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "batch_loss = list()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    shuffle=False,\n",
    "    epochs=config.max_epochs,\n",
    "    verbose=1,\n",
    "    batch_size=config.max_batch_size,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_begin=None,\n",
    "            on_epoch_end=None,\n",
    "            on_batch_begin=None,\n",
    "            on_batch_end=lambda batch, logs=None: batch_loss.append(logs['loss']),\n",
    "            on_train_begin=None,\n",
    "            on_train_end=None,\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9924630522727966,\n",
       " 0.5416995882987976,\n",
       " 0.3870604932308197,\n",
       " 0.2904958426952362,\n",
       " 0.23416030406951904,\n",
       " 0.19666725397109985,\n",
       " 0.16890378296375275,\n",
       " 0.14811253547668457,\n",
       " 0.13364611566066742,\n",
       " 0.12047319114208221,\n",
       " 0.1137012168765068,\n",
       " 0.10453721880912781,\n",
       " 0.10512326657772064,\n",
       " 0.09761984646320343,\n",
       " 0.09150534123182297,\n",
       " 0.08656332641839981,\n",
       " 0.08227597177028656,\n",
       " 0.07913236320018768,\n",
       " 0.07658860832452774,\n",
       " 0.07337412238121033,\n",
       " 0.07078462839126587,\n",
       " 0.06784328818321228,\n",
       " 0.06561852991580963,\n",
       " 0.06305984407663345,\n",
       " 0.07602135092020035,\n",
       " 0.07381964474916458,\n",
       " 0.07150454819202423,\n",
       " 0.07906987518072128,\n",
       " 0.07637372612953186,\n",
       " 0.07708169519901276,\n",
       " 0.0757325068116188,\n",
       " 0.07423459738492966,\n",
       " 0.07207231223583221,\n",
       " 0.06997106224298477,\n",
       " 0.0681360736489296,\n",
       " 0.08299694210290909,\n",
       " 0.08258632570505142,\n",
       " 0.080537348985672,\n",
       " 0.07876134663820267,\n",
       " 0.07714874297380447,\n",
       " 0.0752696841955185,\n",
       " 0.07869915664196014,\n",
       " 0.07725026458501816,\n",
       " 0.07620889693498611,\n",
       " 0.07453171908855438,\n",
       " 0.08414769917726517,\n",
       " 0.08353672921657562,\n",
       " 0.08202508836984634,\n",
       " 0.08051387220621109,\n",
       " 0.0819481834769249,\n",
       " 0.08072677999734879,\n",
       " 0.07969307899475098]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.99246305>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0909361>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.077782236>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0008019701>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.008818111>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.009202028>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0023229208>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0025738871>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.017914716>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0019168521>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.04598143>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0037332498>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.11215585>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.548346e-05>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.005902314>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.01243301>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0136783>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.02569107>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.030800983>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.012298945>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.018994637>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.006075294>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.016673803>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0042101624>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.38709748>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.01877692>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.011312146>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.2833337>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0008814119>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.09761295>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.035256922>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.027799256>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.002879129>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0006299663>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0057462705>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.60312754>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.06780412>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.004725218>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.011273045>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.014257141>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0001076098>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.2193074>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.016396645>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.031430148>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.00073579076>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5168667>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.055431988>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.010978225>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.007975354>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.15222977>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.019656809>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.02697427>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ec44ab71e55dcbd77e8108daeda65d530bc364476bc79d734b0ae94bd7b36be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
