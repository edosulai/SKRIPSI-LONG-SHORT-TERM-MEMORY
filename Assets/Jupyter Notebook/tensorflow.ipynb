{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def set_config(config_dict):\n",
    "    config = Config()\n",
    "    config.__dict__ = config_dict\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    'row_start': '2004-10-16',\n",
    "    'row_end': '2004-12-14',\n",
    "    \"timesteps\": 2,\n",
    "    \"max_batch_size\": 1,\n",
    "    \"layer_size\": 1,\n",
    "    \"unit_size\": 1,\n",
    "    \"dropout\": 0,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_epochs\": 1,\n",
    "    \"time_col\": 'tanggal',\n",
    "    \"feature\": ['rr'],\n",
    "})\n",
    "\n",
    "\n",
    "def train_test_split(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    # for i in range(len(dataset)-time_step-1):\n",
    "    for i in range(len(dataset) - time_step):\n",
    "        dataX.append(dataset[i:(i + time_step), 0])\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def proyeksi_split(dataset, time_step=1):\n",
    "    dataX = []\n",
    "    for i in range(len(dataset) - time_step + 1):\n",
    "        dataX.append(dataset[i:(i + time_step), 0])\n",
    "    return np.array(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = pd.read_csv('../Data/1985-2021.csv').replace(to_replace=[8888, 9999, 2555], value=np.nan)\n",
    "DATASETS = DATASETS.loc[\n",
    "  (DATASETS[config.time_col] >= config.row_start) & \n",
    "  # (DATASETS[config.time_col] <= (datetime.strptime(config.row_end, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "  (DATASETS[config.time_col] <= config.row_end)\n",
    "]\n",
    "DATASETS.interpolate(inplace=True)\n",
    "\n",
    "datelist = np.array([datetime.strptime(date, '%Y-%m-%d').date() for date in list(DATASETS[config.time_col])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2004, 12, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datelist[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = DATASETS[config.feature]\n",
    "vector_featureset = featureset.values\n",
    "\n",
    "scaller = MinMaxScaler()\n",
    "vector_featureset_scaled = scaller.fit_transform(vector_featureset)\n",
    "\n",
    "train_size = int(vector_featureset_scaled.size * 0.9)\n",
    "trainset, testset = vector_featureset_scaled[0:train_size], vector_featureset_scaled[train_size:vector_featureset_scaled.size]\n",
    "traindateset, testdateset = datelist[0:train_size], datelist[train_size:datelist.size]\n",
    "\n",
    "X_train, y_train = train_test_split(trainset, time_step=config.timesteps)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], len(config.feature), X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3]+[4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (1, 1)                    16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# y_pred_loss = list()\n",
    "# y_true_loss = list()\n",
    "# loss = list()\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    # y_pred_loss.append(y_pred)\n",
    "    # y_true_loss.append(y_true)\n",
    "    # loss.append(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true)))\n",
    "    return tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true))\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(mean_squared_error(y_pred, y_true))\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "for i in range(0, config.layer_size):\n",
    "    model.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            units=config.unit_size,\n",
    "            return_sequences=False if i == config.layer_size - 1 else True,\n",
    "            batch_input_shape=(config.max_batch_size, len(config.feature), config.timesteps),\n",
    "            go_backwards=True,\n",
    "            dropout=config.dropout,\n",
    "            # weights=[\n",
    "            #     np.array([\n",
    "            #         [0.5774, 0.5774, 0.5774, 0.5774],\n",
    "            #         [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "            #     ]),\n",
    "            #     np.array([\n",
    "            #         [0.5774, 0.5774, 0.5774, 0.5774]\n",
    "            #     ]),\n",
    "            #     np.zeros([4])\n",
    "            # ]\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=config.learning_rate),\n",
    "        loss=mean_squared_error,\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 59ms/step - loss: 0.1148\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "batch_loss = list()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    shuffle=False,\n",
    "    epochs=config.max_epochs,\n",
    "    verbose=1,\n",
    "    batch_size=config.max_batch_size,\n",
    "    # callbacks=[\n",
    "    #     tf.keras.callbacks.LambdaCallback(\n",
    "    #         on_epoch_begin=None,\n",
    "    #         on_epoch_end=None,\n",
    "    #         on_batch_begin=None,\n",
    "    #         on_batch_end=lambda batch, logs=None: batch_loss.append(logs['loss']),\n",
    "    #         on_train_begin=None,\n",
    "    #         on_train_end=None,\n",
    "    #     )\n",
    "    # ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test = train_test_split(testset, time_step=config.timesteps)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], len(config.feature), X_test.shape[1]))\n",
    "\n",
    "# results = model.evaluate(\n",
    "#     X_test,\n",
    "#     y_test,\n",
    "#     verbose=1,\n",
    "#     batch_size=config.max_batch_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sulai\\Documents\\Skripsi\\Assets\\Jupyter Notebook\\tensorflow.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sulai/Documents/Skripsi/Assets/Jupyter%20Notebook/tensorflow.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpylab\u001b[39;00m \u001b[39mimport\u001b[39;00m rcParams\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sulai/Documents/Skripsi/Assets/Jupyter%20Notebook/tensorflow.ipynb#ch0000000?line=2'>3</a>\u001b[0m rcParams[\u001b[39m'\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m14\u001b[39m, \u001b[39m5\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sulai/Documents/Skripsi/Assets/Jupyter%20Notebook/tensorflow.ipynb#ch0000000?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(PREDICTIONS\u001b[39m.\u001b[39mloc[START_DATE_FOR_PLOTTING:]\u001b[39m.\u001b[39mindex, PREDICTIONS\u001b[39m.\u001b[39mloc[START_DATE_FOR_PLOTTING:][config\u001b[39m.\u001b[39mfeature], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39morange\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProyeksi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sulai/Documents/Skripsi/Assets/Jupyter%20Notebook/tensorflow.ipynb#ch0000000?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(HISTORY\u001b[39m.\u001b[39mloc[START_DATE_FOR_PLOTTING:]\u001b[39m.\u001b[39mindex, HISTORY\u001b[39m.\u001b[39mloc[START_DATE_FOR_PLOTTING:][config\u001b[39m.\u001b[39mfeature], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHistori\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sulai/Documents/Skripsi/Assets/Jupyter%20Notebook/tensorflow.ipynb#ch0000000?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39maxvline(x \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(PREDICTIONS\u001b[39m.\u001b[39mindex), color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "\n",
    "plt.plot(PREDICTIONS.loc[START_DATE_FOR_PLOTTING:].index, PREDICTIONS.loc[START_DATE_FOR_PLOTTING:][config.feature], color='orange', label='Proyeksi')\n",
    "plt.plot(HISTORY.loc[START_DATE_FOR_PLOTTING:].index, HISTORY.loc[START_DATE_FOR_PLOTTING:][config.feature], color='b', label='Histori')\n",
    "\n",
    "plt.axvline(x = min(PREDICTIONS.index), color='green', linewidth=2, linestyle='--')\n",
    "plt.grid(which='major', color='#cccccc', alpha=0.5)\n",
    "\n",
    "plt.title('Prediksi dan Histori Curah Hujan', family='Arial', fontsize=12)\n",
    "plt.xlabel('Timeline', family='Arial', fontsize=10)\n",
    "plt.ylabel('Tingkat Curah Hujan', family='Arial', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.legend(shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ec44ab71e55dcbd77e8108daeda65d530bc364476bc79d734b0ae94bd7b36be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
